{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([-6.7933, -4.8968, -6.5155, -7.3361, -2.6660]) cost: 31667.597656\n",
      "Epoch    1/20 hypothesis: tensor([62.7036, 78.6330, 75.7880, 82.2903, 61.0462]) cost: 9926.266602\n",
      "Epoch    2/20 hypothesis: tensor([101.6124, 125.3983, 121.8667, 132.4688,  96.7163]) cost: 3111.513916\n",
      "Epoch    3/20 hypothesis: tensor([123.3960, 151.5805, 147.6645, 160.5620, 116.6867]) cost: 975.451355\n",
      "Epoch    4/20 hypothesis: tensor([135.5919, 166.2389, 162.1078, 176.2903, 127.8673]) cost: 305.908539\n",
      "Epoch    5/20 hypothesis: tensor([142.4200, 174.4456, 170.1940, 185.0960, 134.1269]) cost: 96.042488\n",
      "Epoch    6/20 hypothesis: tensor([146.2428, 179.0401, 174.7213, 190.0260, 137.6314]) cost: 30.260750\n",
      "Epoch    7/20 hypothesis: tensor([148.3830, 181.6125, 177.2559, 192.7861, 139.5934]) cost: 9.641701\n",
      "Epoch    8/20 hypothesis: tensor([149.5814, 183.0526, 178.6749, 194.3314, 140.6919]) cost: 3.178671\n",
      "Epoch    9/20 hypothesis: tensor([150.2523, 183.8588, 179.4694, 195.1966, 141.3068]) cost: 1.152871\n",
      "Epoch   10/20 hypothesis: tensor([150.6279, 184.3102, 179.9142, 195.6810, 141.6511]) cost: 0.517863\n",
      "Epoch   11/20 hypothesis: tensor([150.8383, 184.5629, 180.1633, 195.9521, 141.8438]) cost: 0.318801\n",
      "Epoch   12/20 hypothesis: tensor([150.9561, 184.7043, 180.3027, 196.1040, 141.9516]) cost: 0.256388\n",
      "Epoch   13/20 hypothesis: tensor([151.0221, 184.7835, 180.3808, 196.1890, 142.0120]) cost: 0.236821\n",
      "Epoch   14/20 hypothesis: tensor([151.0591, 184.8278, 180.4245, 196.2366, 142.0458]) cost: 0.230660\n",
      "Epoch   15/20 hypothesis: tensor([151.0798, 184.8526, 180.4490, 196.2632, 142.0646]) cost: 0.228719\n",
      "Epoch   16/20 hypothesis: tensor([151.0914, 184.8664, 180.4627, 196.2782, 142.0752]) cost: 0.228095\n",
      "Epoch   17/20 hypothesis: tensor([151.0980, 184.8741, 180.4704, 196.2865, 142.0811]) cost: 0.227880\n",
      "Epoch   18/20 hypothesis: tensor([151.1017, 184.8784, 180.4747, 196.2912, 142.0843]) cost: 0.227799\n",
      "Epoch   19/20 hypothesis: tensor([151.1038, 184.8808, 180.4772, 196.2939, 142.0861]) cost: 0.227762\n",
      "Epoch   20/20 hypothesis: tensor([151.1050, 184.8821, 180.4786, 196.2953, 142.0871]) cost: 0.227732\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 훈련용 데이터\n",
    "x_train = np.array([\n",
    "    [73, 80, 75], \n",
    "    [93, 88, 93], \n",
    "    [89, 91, 90], \n",
    "    [96, 98, 100],   \n",
    "    [73, 66, 70]\n",
    "])\n",
    "y_train = np.array([152, 185, 180, 196, 142])\n",
    "\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(np.expand_dims(y_train, 1))\n",
    "\n",
    "# model 및 optimizer 설정\n",
    "model = nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    # predict 및 cost 계산\n",
    "    y_pred = model(x_train)\n",
    "    cost = F.mse_loss(y_pred, y_train)\n",
    "    \n",
    "    # parameter 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 로그 출력\n",
    "    print('Epoch {:4d}/{} hypothesis: {} cost: {:.6f}'.format(epoch, nb_epochs, y_pred.squeeze().detach(), cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 모델 설계\n",
    "class LinearModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = LinearModel()\n",
    "\n",
    "# 훈련용 데이터\n",
    "x_train = np.array([\n",
    "    [73, 80, 75], \n",
    "    [93, 88, 93], \n",
    "    [89, 91, 90], \n",
    "    [96, 98, 100],   \n",
    "    [73, 66, 70]\n",
    "])\n",
    "y_train = np.array([152, 185, 180, 196, 142])\n",
    "\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(np.expand_dims(y_train, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 hypothesis: tensor([151.6439, 184.4528, 180.5883, 196.9684, 140.9837]) cost: 0.548598\n",
      "Epoch  500/2000 hypothesis: tensor([151.5797, 184.4980, 180.5701, 196.9436, 141.0527]) cost: 0.508307\n",
      "Epoch 1000/2000 hypothesis: tensor([151.5242, 184.5371, 180.5546, 196.9210, 141.1138]) cost: 0.476340\n",
      "Epoch 1500/2000 hypothesis: tensor([151.4764, 184.5710, 180.5414, 196.9001, 141.1679]) cost: 0.450790\n",
      "Epoch 2000/2000 hypothesis: tensor([151.4353, 184.6004, 180.5302, 196.8809, 141.2158]) cost: 0.430138\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    # predict 및 cost 계산\n",
    "    y_pred = model(x_train)\n",
    "    cost = F.mse_loss(y_pred, y_train)\n",
    "    \n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 backward 연산\n",
    "    cost.backward()\n",
    "    # parameters 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    # 로그 출력\n",
    "    if epoch%500 == 0:\n",
    "        print('Epoch {:4d}/{} hypothesis: {} cost: {:.6f}'.format(epoch, nb_epochs, y_pred.squeeze().detach(), cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용 데이터\n",
    "x_train = np.array([\n",
    "    [73, 80, 75], \n",
    "    [93, 88, 93], \n",
    "    [89, 91, 90], \n",
    "    [96, 98, 100],   \n",
    "    [73, 66, 70]\n",
    "])\n",
    "y_train = np.array([152, 185, 180, 196, 142])\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(np.expand_dims(y_train, 1))\n",
    "\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/2 Cost: 0.048699\n",
      "Epoch    0/20 Batch 2/2 Cost: 0.500550\n",
      "Epoch    1/20 Batch 1/2 Cost: 0.337825\n",
      "Epoch    1/20 Batch 2/2 Cost: 0.059238\n",
      "Epoch    2/20 Batch 1/2 Cost: 0.357047\n",
      "Epoch    2/20 Batch 2/2 Cost: 0.027849\n",
      "Epoch    3/20 Batch 1/2 Cost: 0.259582\n",
      "Epoch    3/20 Batch 2/2 Cost: 0.207597\n",
      "Epoch    4/20 Batch 1/2 Cost: 0.357530\n",
      "Epoch    4/20 Batch 2/2 Cost: 0.074208\n",
      "Epoch    5/20 Batch 1/2 Cost: 0.297111\n",
      "Epoch    5/20 Batch 2/2 Cost: 0.242953\n",
      "Epoch    6/20 Batch 1/2 Cost: 0.093187\n",
      "Epoch    6/20 Batch 2/2 Cost: 0.488001\n",
      "Epoch    7/20 Batch 1/2 Cost: 0.337616\n",
      "Epoch    7/20 Batch 2/2 Cost: 0.059147\n",
      "Epoch    8/20 Batch 1/2 Cost: 0.254380\n",
      "Epoch    8/20 Batch 2/2 Cost: 0.280890\n",
      "Epoch    9/20 Batch 1/2 Cost: 0.109078\n",
      "Epoch    9/20 Batch 2/2 Cost: 0.475385\n",
      "Epoch   10/20 Batch 1/2 Cost: 0.175813\n",
      "Epoch   10/20 Batch 2/2 Cost: 0.395611\n",
      "Epoch   11/20 Batch 1/2 Cost: 0.208443\n",
      "Epoch   11/20 Batch 2/2 Cost: 0.373396\n",
      "Epoch   12/20 Batch 1/2 Cost: 0.347671\n",
      "Epoch   12/20 Batch 2/2 Cost: 0.068205\n",
      "Epoch   13/20 Batch 1/2 Cost: 0.220853\n",
      "Epoch   13/20 Batch 2/2 Cost: 0.344287\n",
      "Epoch   14/20 Batch 1/2 Cost: 0.041614\n",
      "Epoch   14/20 Batch 2/2 Cost: 0.522835\n",
      "Epoch   15/20 Batch 1/2 Cost: 0.128673\n",
      "Epoch   15/20 Batch 2/2 Cost: 0.430564\n",
      "Epoch   16/20 Batch 1/2 Cost: 0.209578\n",
      "Epoch   16/20 Batch 2/2 Cost: 0.449932\n",
      "Epoch   17/20 Batch 1/2 Cost: 0.195341\n",
      "Epoch   17/20 Batch 2/2 Cost: 0.385305\n",
      "Epoch   18/20 Batch 1/2 Cost: 0.266767\n",
      "Epoch   18/20 Batch 2/2 Cost: 0.298987\n",
      "Epoch   19/20 Batch 1/2 Cost: 0.336620\n",
      "Epoch   19/20 Batch 2/2 Cost: 0.215114\n",
      "Epoch   20/20 Batch 1/2 Cost: 0.100280\n",
      "Epoch   20/20 Batch 2/2 Cost: 0.496688\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "for epoch in range(nb_epochs+1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_train, y_train = samples\n",
    "        y_pred = model(x_train)\n",
    "        \n",
    "        cost = F.mse_loss(y_pred, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, batch_idx+1, len(dataloader), cost.item()\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
