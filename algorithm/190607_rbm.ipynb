{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ising:\n",
    "    \n",
    "    # 초기화\n",
    "    def __init__(self, num_row, num_col):\n",
    "        self.num_row, self.num_col = num_row, num_col\n",
    "        self.gen_system()\n",
    "        \n",
    "    # (r x s) System configuration을 랜덤으로 생성    \n",
    "    def gen_system(self):\n",
    "        self.spins = torch.where(torch.rand(self.num_row, self.num_col) < 0.5, torch.ones(1), -torch.ones(1))\n",
    "    \n",
    "    # System의 Hamiltonian를 계산\n",
    "    def Hamiltonian(self):\n",
    "        H, J = 0., 1.\n",
    "        for i, j in product(range(self.num_row), range(self.num_col)):\n",
    "            for i_nhb, j_nhb in self.get_neighbors(i, j):\n",
    "                H -= J*self.spins[i_nhb, j_nhb]*self.spins[i, j]\n",
    "        return H/2\n",
    "            \n",
    "    # 격자 (i, j)의 neighbors를 리턴\n",
    "    def get_neighbors(self, i, j):\n",
    "        assert (i >= 0) and (i <= self.num_row-1) and (j >= 0) and (j <= self.num_col-1)\n",
    "        nhb = []\n",
    "        if j != self.num_col - 1: nhb.append([i, j+1])\n",
    "        if j != 0: nhb.append([i, j-1])\n",
    "        if i != self.num_row - 1: nhb.append([i+1, j])\n",
    "        if i != 0: nhb.append([i-1, j])\n",
    "        return nhb\n",
    "    \n",
    "    # n개의 데이터 생성 (Hamiltonian이 낮을수록 생성 확률 높음)\n",
    "    def gen_train_data(self, num_data):\n",
    "        self.gen_system()\n",
    "        H = self.Hamiltonian()\n",
    "        data = ((1-self.spins.view(-1))/2).unsqueeze(0)\n",
    "        for _ in range(num_data-1):\n",
    "            self.gen_system()\n",
    "            H_new = self.Hamiltonian()\n",
    "            p = torch.clamp(torch.exp(-(H_new-H)), max=1)\n",
    "            if torch.rand(1) < p:\n",
    "                v = ((1-self.spins.view(-1))/2).unsqueeze(0)\n",
    "                H = H_new\n",
    "            else:\n",
    "                v = data[-1].unsqueeze(0)  \n",
    "            data = torch.cat([data, v])\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the RBM Architecture (weights, biases)\n",
    "class RBM():\n",
    "    \n",
    "    # Initiate RBM parameters\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(nh)\n",
    "        self.b = torch.randn(nv)\n",
    "    \n",
    "    def Hamiltonian(self, v, h): \n",
    "        ah = torch.dot(self.a, h)\n",
    "        bv = torch.dot(self.b, v)\n",
    "        hWv = torch.dot(h, torch.mv(self.W, v))\n",
    "        H = - ah - bv - hWv\n",
    "        return H\n",
    "    \n",
    "    def FreeEnergy(self, v):\n",
    "        bv = torch.dot(self.b, v)\n",
    "        Wv = torch.mv(self.W, v)\n",
    "        F = - bv\n",
    "        for i in range(Wv.size()[0]):\n",
    "            F -= torch.log(1 + torch.exp(self.a[i] + Wv[i]))\n",
    "        return F\n",
    "    \n",
    "    # Calculate p(v = D[i]) using Softmax\n",
    "    def p_v(self, D):\n",
    "        # Free Energies of each v = D[i]\n",
    "        F = torch.tensor(D.size()[0])\n",
    "        for i in range(D.size()[0]):\n",
    "            F[i] = self.FreeEnergy(D[i])\n",
    "            \n",
    "        # p(v = D[i]) = Softmax(-F)[i] = exp(-F[i])/Z\n",
    "        p_v = F.softmax(- F, dim = 0)\n",
    "        return p_v\n",
    "    \n",
    "    # Calculate Negative Log-Likelihood using log_softmax\n",
    "    def NLL(self, D):\n",
    "        # Free Energies of each v = D[i]\n",
    "        F = torch.zeros(D.size()[0])\n",
    "        for i in range(D.size()[0]):\n",
    "            F[i] = self.FreeEnergy(D[i])\n",
    "            \n",
    "        # p(v = D[i]) = Softmax(-F)[i] = exp(-F[i])/Z\n",
    "        LSM = F.log_softmax(- F, dim = 0)\n",
    "        NLL = - torch.mean(LSM)\n",
    "        return NLL\n",
    "    \n",
    "    def sigmoid_i(self, D, idx):\n",
    "        a = self.a\n",
    "        WD_i = torch.mv(self.W, D[idx])\n",
    "        sigmoid = torch.sigmoid(a + WD_i)\n",
    "        return sigmoid\n",
    "    \n",
    "    def grad_F_i(self, D, idx, param):\n",
    "        \n",
    "        grad_F_i = torch.zeros_like(param)\n",
    "        \n",
    "        if param == self.W:\n",
    "            for j in range(grad_F_i.size()[0]):\n",
    "                for k in range(grad_F_i.zie()[1]):\n",
    "                    grad_F_i[j,k] = - self.sigmoid_i(D, idx)[j] * D[idx][k]\n",
    "        \n",
    "        elif param == self.a:\n",
    "            for j in range(grad_F_i.size()[0]):\n",
    "                grad_F_i[j] = - self.sigmoid_i(D, idx)[j]\n",
    "        \n",
    "        elif param == self.b:\n",
    "            for j in range(grad_F_i.size()[0]):\n",
    "                grad_F_i[j] = - D[idx][j]\n",
    "        \n",
    "        return grad_F_i\n",
    "        \n",
    "    # Gradients of Negative Log-Likelihood\n",
    "    def grad_NLL(self, D, param):\n",
    "        \n",
    "        grad_NLL = torch.zeros_like(param)\n",
    "        nData = D.size()[0]\n",
    "        \n",
    "        for idx in range(nData):\n",
    "            grad_NLL += (1 / nData - self.p_v(D)[idx]) * self.grad_F_i(D, idx, param)\n",
    "        \n",
    "        return grad_NLL\n",
    "    \n",
    "    # Update the RBM parameters\n",
    "    def update(self, D, learning_rate):\n",
    "\n",
    "        grad_NLL_w = self.grad_NLL(D, self.W)\n",
    "        grad_NLL_a = self.grad_NLL(D, self.a)\n",
    "        grad_NLL_b = self.grad_NLL(D, self.b)\n",
    "        \n",
    "        self.W -= learning_rate * grad_NLL_w\n",
    "        self.a -= learning_rate * grad_NLL_a\n",
    "        self.b -= learning_rate * grad_NLL_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 0., 0., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ising = Ising(3, 3)\n",
    "train_data = ising.gen_train_data(10)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(D.size()[1], nh = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: W = tensor([[ 0.1156,  1.8399, -0.6726,  2.0601, -0.3161, -0.4336, -1.5100, -1.3203,\n",
      "         -0.4472],\n",
      "        [-0.7756,  0.3477, -0.3959,  0.5800, -0.6545, -1.4602,  0.6614, -0.1726,\n",
      "         -0.8117],\n",
      "        [ 1.1187, -1.2118,  0.0658,  0.9374, -1.2990, -1.7850,  0.0266,  0.1419,\n",
      "         -1.1713],\n",
      "        [-0.8976, -1.9839, -1.2400,  2.0431,  0.5771, -1.2451,  0.2496, -1.8348,\n",
      "         -0.3367]])\n",
      "\t a = tensor([-0.6742,  0.0440,  1.1494,  0.2319])\n",
      "\t b = tensor([ 0.6227,  0.0780, -1.0363, -0.7545, -0.4662,  2.0998, -1.5583,  1.3050,\n",
      "        -1.3130])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-573-42841e941b37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch {}: W = {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-272-e6abd4036e70>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, D, learning_rate)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mgrad_NLL_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_NLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mgrad_NLL_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_NLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mgrad_NLL_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_NLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-272-e6abd4036e70>\u001b[0m in \u001b[0;36mgrad_NLL\u001b[1;34m(self, D, param)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mgrad_NLL\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnData\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_F_i\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_NLL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-272-e6abd4036e70>\u001b[0m in \u001b[0;36mp_v\u001b[1;34m(self, D)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreeEnergy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# p(v = D[i]) = Softmax(-F)[i] = exp(-F[i])/Z\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
     ]
    }
   ],
   "source": [
    "# Train the RBM\n",
    "num_epoch = 100\n",
    "#batch_size = 1\\\n",
    "lr = 1e-3  #learning_rate\n",
    "\n",
    "for epoch in range(0, num_epoch + 1):\n",
    "        \n",
    "    if epoch > 0:\n",
    "        rbm.update(D, lr)\n",
    "    \n",
    "    print('epoch {}: W = {}'.format(epoch, rbm.W))\n",
    "    print('\\t a = {}'.format(rbm.a))\n",
    "    print('\\t b = {}'.format(rbm.b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
