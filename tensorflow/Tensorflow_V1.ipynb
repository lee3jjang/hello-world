{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 연습1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "c = tf.add(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n",
      "[10, 32, 42]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "print(sess.run([a,b,c]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 3])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2,3],[4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([3,2]))\n",
    "b = tf.Variable(tf.random_normal([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable([[0.1, 0.1], [0.2, 0.2], [0.3, 0.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n",
      "[[0.1 0.1]\n",
      " [0.2 0.2]\n",
      " [0.3 0.3]]\n",
      "[-0.41599578  0.823621  ]\n",
      "[[0.9840043 2.2236211]\n",
      " [2.7840042 4.023621 ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(x_data)\n",
    "print(sess.run(W))\n",
    "print(sess.run(b))\n",
    "print(sess.run(expr, feed_dict={X: x_data}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n",
      "[[0.1 0.1]\n",
      " [0.2 0.2]\n",
      " [0.3 0.3]]\n",
      "[ 1.0932581 -1.3807714]\n",
      "[[2.4932582 0.0192287]\n",
      " [4.293258  1.8192286]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(x_data)\n",
    "    print(sess.run(W))\n",
    "    print(sess.run(b))\n",
    "    print(sess.run(expr, feed_dict={X: x_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 연습2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([1], -1., 1.))\n",
    "b = tf.Variable(tf.random_uniform([1], -1., 1.))\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "\n",
    "hypothesis = W*X + b\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(cost)\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02452594, 0.32873366, 0.98029484])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.5832546*np.array([1,2,3]) + 0.2601378 - np.array([1,2,3]))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5832546]\n",
      "[0.2601378]\n",
      "[0.02452595 0.3287337  0.980295  ]\n",
      "[0.8433924 1.426647  2.0099015]\n",
      "0.4445182\n",
      "[None, 0.4445182]\n",
      "==========\n",
      "[0.8681619]\n",
      "[0.3748084]\n",
      "0.023937894\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(W))\n",
    "    print(sess.run(b))\n",
    "    print(sess.run(tf.square(hypothesis - Y), feed_dict={X: x_data, Y: y_data}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: x_data}))\n",
    "    print(sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "    print(sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data}))\n",
    "    print('='*10)\n",
    "    print(sess.run(W))\n",
    "    print(sess.run(b))\n",
    "    print(sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38719082 1.25959492 2.13199902] [1 2 3] 0.5590534916210128\n",
      "[0.84844672 2.03402572 3.21960472] [1 2 3] 0.024117459782185074\n"
     ]
    }
   ],
   "source": [
    "y_pred = 0.8724041*np.array([1,2,3])-0.48521328\n",
    "y = np.array([1,2,3])\n",
    "cost_1 = np.mean((y_pred-y)**2)\n",
    "print(y_pred, y, cost_1)\n",
    "y_pred_2 = 1.185579*np.array([1,2,3])-0.33713228\n",
    "cost_2 = np.mean((y_pred_2-y)**2)\n",
    "print(y_pred_2, y, cost_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.030397266 [0.79189765] [0.45527124]\n",
      "100 0.00023184984 [0.9823152] [0.04020179]\n",
      "200 1.7851129e-06 [0.99844825] [0.00352758]\n",
      "300 1.3738865e-08 [0.99986386] [0.00030952]\n",
      "400 1.0554402e-10 [0.999988] [2.716525e-05]\n",
      "500 9.284425e-13 [0.999999] [2.3935595e-06]\n",
      "600 2.3684757e-14 [0.9999999] [2.875297e-07]\n",
      "700 0.0 [1.] [5.7058315e-08]\n",
      "800 0.0 [1.] [5.7058315e-08]\n",
      "900 0.0 [1.] [5.7058315e-08]\n",
      "1000 0.0 [1.] [5.7058315e-08]\n",
      "X: 5, Y: [5.]\n",
      "X: 2.5, Y: [2.5]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 여기서 출력되는 cost는 optimization 실행 후의 cost임\n",
    "    # 같이 실행([train_op, cost])하면 optimization 실행 전의 cost가 출력된\n",
    "    for step in range(1001):\n",
    "        #sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "        cost_val = sess.run(cost, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val, sess.run(W), sess.run(b))\n",
    "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))        \n",
    "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 연습3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [털, 날개]\n",
    "x_data = np.array([[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]])\n",
    "y_data = np.array([\n",
    "    [1,0,0],\n",
    "    [0,1,0],\n",
    "    [0,0,1],\n",
    "    [1,0,0],\n",
    "    [1,0,0],\n",
    "    [0,0,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(tf.random_uniform([2,3],-1,1))\n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "L = tf.nn.relu(tf.matmul(X,W)+b)\n",
    "model = tf.nn.softmax(L)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(model), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 1.1844134\n",
      "200 1.1413332\n",
      "300 1.1103493\n",
      "400 1.0992799\n",
      "500 1.0917565\n",
      "600 1.0847609\n",
      "700 1.0781925\n",
      "800 1.0719794\n",
      "900 1.0660701\n",
      "1000 1.0604271\n",
      "예측값: [0 1 1 0 0 0]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도: 66.67%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1000):\n",
    "        sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "        if (step+1)%100 == 0:\n",
    "            print(step+1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))  \n",
    "            \n",
    "    prediction = tf.argmax(model, axis=1)\n",
    "    target = tf.argmax(Y, axis=1)\n",
    "    print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "    print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "    is_correct = tf.equal(prediction, target)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    print('정확도: {:.2f}%'.format(sess.run(accuracy*100, feed_dict={X: x_data, Y: y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666667"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0, 1, 1, 0, 0, 0])\n",
    "b = np.array([0, 1, 2, 0, 0, 2])\n",
    "c = (a == b).astype(np.float32)\n",
    "np.mean(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "========================================\n",
      "[[ 0.23982978 -0.8846631   0.32417893]\n",
      " [ 0.10176492 -0.3515582   0.16995478]]\n",
      "[0. 0. 0.]\n",
      "========================================\n",
      "[[ 0.          0.          0.        ]\n",
      " [ 0.23982978 -0.8846631   0.32417893]\n",
      " [ 0.3415947  -1.2362213   0.4941337 ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.10176492 -0.3515582   0.16995478]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.23982978 0.         0.32417893]\n",
      " [0.3415947  0.         0.4941337 ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.10176492 0.         0.16995478]]\n",
      "========================================\n",
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.34785387 0.27367812 0.37846804]\n",
      " [0.34777477 0.24714135 0.40508386]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33626893 0.3037322  0.35999894]]\n",
      "1.0861591\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(X, feed_dict={X: x_data}))\n",
    "    print(sess.run(Y, feed_dict={Y: y_data}))\n",
    "    print('='*40)\n",
    "    print(sess.run(W))\n",
    "    print(sess.run(b))\n",
    "    print('='*40)\n",
    "    print(sess.run(tf.matmul(X,W)+b, feed_dict={X: x_data}))\n",
    "    print(sess.run(L, feed_dict={X: x_data}))\n",
    "    print('='*40)\n",
    "    print(sess.run(model, feed_dict={X: x_data}))\n",
    "    print(sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.        ]\n",
      " [ 0.23982978 -0.8846631   0.32417893]\n",
      " [ 0.3415947  -1.2362213   0.49413371]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.10176492 -0.3515582   0.16995478]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.23982978 0.         0.32417893]\n",
      " [0.3415947  0.         0.49413371]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.10176492 0.         0.16995478]]\n",
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.34785386 0.27367812 0.37846803]\n",
      " [0.34777479 0.24714134 0.40508387]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33626892 0.30373216 0.35999892]]\n",
      "1.0861591457342197\n",
      "[0 2 2 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0., 0.],\n",
    "              [1., 0.],\n",
    "              [1., 1.],\n",
    "              [0., 0.],\n",
    "              [0., 0.],\n",
    "              [0., 1.]])\n",
    "y = np.array([[1., 0., 0.],\n",
    "              [0., 1., 0.],\n",
    "              [0., 0., 1.],\n",
    "              [1., 0., 0.],\n",
    "              [1., 0., 0.],\n",
    "              [0., 0., 1.]])\n",
    "w = np.array([[ 0.23982978, -0.8846631,   0.32417893],\n",
    "              [ 0.10176492, -0.3515582,   0.16995478]])\n",
    "z = np.matmul(x,w)+np.array([0,0,0])\n",
    "l = np.fmax(z,0)\n",
    "sm = np.exp(l)/np.sum(np.exp(l), axis=1).reshape((6,1))\n",
    "loss = np.mean(-np.sum(y*np.log(sm), axis=1))\n",
    "arg = np.argmax(sm, axis=1)\n",
    "print(z)\n",
    "print(l)\n",
    "print(sm)\n",
    "print(loss)\n",
    "print(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 연습4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0],[1,0],[1,1],[0,0],[0,0],[0,1]])\n",
    "y_data = np.array([\n",
    "    [1,0,0],\n",
    "    [0,1,0],\n",
    "    [0,0,1],\n",
    "    [1,0,0],\n",
    "    [1,0,0],\n",
    "    [0,0,1]\n",
    "])\n",
    "\n",
    "n = 4\n",
    "X = tf.placeholder(tf.float32)\n",
    "W1 = tf.Variable(tf.random_uniform([2,n], -1,1))\n",
    "W2 = tf.Variable(tf.random_uniform([n,3], -1,1))\n",
    "b1 = tf.Variable(tf.zeros([n]))\n",
    "b2 = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "# 출력층에서는 활성화 함수를 잘 안 쓴다고 함\n",
    "L2 = tf.matmul(L1, W2) + b2\n",
    "model = tf.nn.softmax(L2, axis=1)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(model), axis=1))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.00059554237\n",
      "2000 0.00014022145\n",
      "3000 5.4599626e-05\n",
      "4000 2.5590656e-05\n",
      "5000 1.3053522e-05\n",
      "6000 6.993642e-06\n",
      "7000 3.8941794e-06\n",
      "8000 2.1855067e-06\n",
      "9000 1.1920938e-06\n",
      "10000 6.7551963e-07\n",
      "예측값: [0 1 2 0 0 2]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "결과: [ True  True  True  True  True  True]\n",
      "정확도: 100.00%\n",
      "[[ 1.7704268  -0.764212    3.6195383  -0.545701  ]\n",
      " [ 2.7818518  -2.88417    -2.5682533  -0.12653112]]\n",
      "[[-2.6798215  -1.204446    2.974438  ]\n",
      " [ 2.6897655  -1.4241432  -3.102268  ]\n",
      " [-3.0831718   3.261634   -2.458045  ]\n",
      " [ 0.527411    0.9228296  -0.09494901]]\n",
      "[2.5950307e-01 2.8841219e+00 3.4415956e-07 0.0000000e+00]\n",
      "[ 1.333947  -1.6760839 -0.6542709]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(10000):\n",
    "        sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "        if (1+step)%1000 == 0:\n",
    "            print(1+step, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "    \n",
    "    prediction = tf.argmax(model, axis=1)\n",
    "    actual = tf.argmax(Y, axis=1)\n",
    "    print(\"예측값:\", sess.run(prediction, feed_dict={X: x_data}))\n",
    "    print(\"실제값:\", sess.run(actual, feed_dict={Y: y_data}))\n",
    "    \n",
    "    is_correct = tf.equal(prediction, actual)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    \n",
    "    print('결과:', sess.run(is_correct, feed_dict={X: x_data, Y: y_data}))\n",
    "    print('정확도: {:.2f}%'.format(sess.run(accuracy*100, feed_dict={X: x_data, Y: y_data})))\n",
    "    print(sess.run(W1))\n",
    "    print(sess.run(W2))\n",
    "    print(sess.run(b1))\n",
    "    print(sess.run(b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 연습5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('./data.csv', delimiter=',', dtype=np.float32, unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.transpose(data[:2])\n",
    "y_data = np.transpose(data[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2,10], -1,1))\n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "L1 = tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([10,20], -1,1))\n",
    "b2 = tf.Variable(tf.zeros([20]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1,W2)+b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([20,3], -1,1))\n",
    "b3 = tf.Variable(tf.zeros([3]))\n",
    "model = tf.nn.softmax(tf.matmul(L2,W3)+b3, axis=1)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(model), axis=1))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, Cost: 1.953\n",
      "Step: 2, Cost: 1.666\n",
      "Step: 3, Cost: 1.422\n",
      "Step: 4, Cost: 1.225\n",
      "Step: 5, Cost: 1.075\n",
      "Step: 6, Cost: 0.967\n",
      "Step: 7, Cost: 0.888\n",
      "Step: 8, Cost: 0.830\n",
      "Step: 9, Cost: 0.780\n",
      "Step: 10, Cost: 0.737\n",
      "Step: 11, Cost: 0.697\n",
      "Step: 12, Cost: 0.667\n",
      "Step: 13, Cost: 0.641\n",
      "Step: 14, Cost: 0.618\n",
      "Step: 15, Cost: 0.598\n",
      "Step: 16, Cost: 0.580\n",
      "Step: 17, Cost: 0.564\n",
      "Step: 18, Cost: 0.550\n",
      "Step: 19, Cost: 0.535\n",
      "Step: 20, Cost: 0.522\n",
      "Step: 21, Cost: 0.511\n",
      "Step: 22, Cost: 0.501\n",
      "Step: 23, Cost: 0.492\n",
      "Step: 24, Cost: 0.483\n",
      "Step: 25, Cost: 0.474\n",
      "Step: 26, Cost: 0.466\n",
      "Step: 27, Cost: 0.458\n",
      "Step: 28, Cost: 0.450\n",
      "Step: 29, Cost: 0.442\n",
      "Step: 30, Cost: 0.435\n",
      "Step: 31, Cost: 0.428\n",
      "Step: 32, Cost: 0.421\n",
      "Step: 33, Cost: 0.414\n",
      "Step: 34, Cost: 0.407\n",
      "Step: 35, Cost: 0.401\n",
      "Step: 36, Cost: 0.395\n",
      "Step: 37, Cost: 0.388\n",
      "Step: 38, Cost: 0.382\n",
      "Step: 39, Cost: 0.377\n",
      "Step: 40, Cost: 0.371\n",
      "Step: 41, Cost: 0.365\n",
      "Step: 42, Cost: 0.360\n",
      "Step: 43, Cost: 0.355\n",
      "Step: 44, Cost: 0.349\n",
      "Step: 45, Cost: 0.344\n",
      "Step: 46, Cost: 0.339\n",
      "Step: 47, Cost: 0.334\n",
      "Step: 48, Cost: 0.329\n",
      "Step: 49, Cost: 0.324\n",
      "Step: 50, Cost: 0.320\n",
      "Step: 51, Cost: 0.315\n",
      "Step: 52, Cost: 0.311\n",
      "Step: 53, Cost: 0.306\n",
      "Step: 54, Cost: 0.302\n",
      "Step: 55, Cost: 0.297\n",
      "Step: 56, Cost: 0.293\n",
      "Step: 57, Cost: 0.289\n",
      "Step: 58, Cost: 0.285\n",
      "Step: 59, Cost: 0.281\n",
      "Step: 60, Cost: 0.277\n",
      "Step: 61, Cost: 0.273\n",
      "Step: 62, Cost: 0.270\n",
      "Step: 63, Cost: 0.266\n",
      "Step: 64, Cost: 0.262\n",
      "Step: 65, Cost: 0.259\n",
      "Step: 66, Cost: 0.255\n",
      "Step: 67, Cost: 0.252\n",
      "Step: 68, Cost: 0.248\n",
      "Step: 69, Cost: 0.245\n",
      "Step: 70, Cost: 0.242\n",
      "Step: 71, Cost: 0.239\n",
      "Step: 72, Cost: 0.235\n",
      "Step: 73, Cost: 0.232\n",
      "Step: 74, Cost: 0.229\n",
      "Step: 75, Cost: 0.226\n",
      "Step: 76, Cost: 0.223\n",
      "Step: 77, Cost: 0.221\n",
      "Step: 78, Cost: 0.218\n",
      "Step: 79, Cost: 0.215\n",
      "Step: 80, Cost: 0.212\n",
      "Step: 81, Cost: 0.209\n",
      "Step: 82, Cost: 0.207\n",
      "Step: 83, Cost: 0.204\n",
      "Step: 84, Cost: 0.202\n",
      "Step: 85, Cost: 0.199\n",
      "Step: 86, Cost: 0.197\n",
      "Step: 87, Cost: 0.194\n",
      "Step: 88, Cost: 0.192\n",
      "Step: 89, Cost: 0.190\n",
      "Step: 90, Cost: 0.187\n",
      "Step: 91, Cost: 0.185\n",
      "Step: 92, Cost: 0.183\n",
      "Step: 93, Cost: 0.181\n",
      "Step: 94, Cost: 0.178\n",
      "Step: 95, Cost: 0.176\n",
      "Step: 96, Cost: 0.174\n",
      "Step: 97, Cost: 0.172\n",
      "Step: 98, Cost: 0.170\n",
      "Step: 99, Cost: 0.168\n",
      "Step: 100, Cost: 0.166\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.global_variables())\n",
    "ckpt = tf.train.get_checkpoint_state('./model')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "        \n",
    "    for step in range(100):\n",
    "        sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "        print('Step: {}, Cost: {:.3f}'.format(sess.run(global_step), sess.run(cost, feed_dict={X: x_data, Y: y_data})))\n",
    "            \n",
    "    saver.save(sess, './model/cnn.ckpt', global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 연습6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('./data.csv', delimiter=',', unpack=True, dtype=np.float32)\n",
    "x_data = np.transpose(data[:2])\n",
    "y_data = np.transpose(data[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.name_scope('layer1'):\n",
    "    W1 = tf.Variable(tf.random_uniform([2, 10], -1,1), name='W1')\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "    \n",
    "with tf.name_scope('layer2'):\n",
    "    W2 = tf.Variable(tf.random_uniform([10, 20], -1,1), name='W2')\n",
    "    L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "    \n",
    "with tf.name_scope('output'):\n",
    "    W3 = tf.Variable(tf.random_uniform([20, 3], -1,1), name='W3')\n",
    "    model = tf.nn.softmax(tf.matmul(L2, W3))\n",
    "    \n",
    "with tf.name_scope('optimizer'):\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(model), axis=1))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    init = tf.global_variables_initializer()\n",
    "    tf.summary.scalar('cost', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\\cnn.ckpt-100\n",
      "0.5497425\n",
      "0.5496932\n",
      "0.54965216\n",
      "0.5496184\n",
      "0.5495902\n",
      "0.5495657\n",
      "0.5495443\n",
      "0.54952556\n",
      "0.54950905\n",
      "0.54949456\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    ckpt = tf.train.get_checkpoint_state('./model')\n",
    "    if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "    \n",
    "    for step in range(100):\n",
    "        sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "        if (1+step)%10 == 0:\n",
    "            print(sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "        summary = sess.run(merged, feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=sess.run(global_step))\n",
    "            \n",
    "    saver.save(sess, './model/cnn.ckpt', global_step=global_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
