{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import random\n",
    "import time\n",
    "import urllib.request\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARGUMENTS\n",
    "keyword = 'DB손해보험' # 검색 키워드\n",
    "pages = 5 # 검색 페이지 수\n",
    "\n",
    "# result 폴더 생성\n",
    "if not any(['result' == s for s in os.listdir('.')]):\n",
    "    os.mkdir('./result')\n",
    "\n",
    "# 페이지별 루프\n",
    "result = list()\n",
    "basedate = datetime.now().strftime('%Y%m%d') # 수집일자\n",
    "for page in range(1, pages+1):\n",
    "    \n",
    "    # 페이지 얻기\n",
    "    time.sleep(random.random()*3) # 딜레이\n",
    "    url = 'https://www.google.co.kr/search?q={}&tbm=nws&start={}'.format(urllib.parse.quote(keyword), 10*(page-1))\n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders=[('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36')]\n",
    "    res = opener.open(url)\n",
    "    html = res.read()\n",
    "\n",
    "    # 파일 저장\n",
    "    with open('./result/google_search_{}_{}_{}.html'.format(basedate, keyword, page), 'wb') as f:\n",
    "        f.write(html)\n",
    "        f.close()\n",
    "\n",
    "    # 데이터 가져오기\n",
    "    soup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    articles = soup.select('div#rso')[0].select('div.g')\n",
    "    data = list()\n",
    "    for article in articles:\n",
    "        article2 = article.select('div.gG0TJc')[0] # ISSUE : gGoTJC 말고 gZQPfd에도 기사 있음\n",
    "        link = article2.select('h3 > a')[0]['href']\n",
    "        title = article2.select('h3 > a')[0].text\n",
    "        press = article2.select('span.xQ82C')[0].text\n",
    "        date =  article2.select('span.f')[0].text\n",
    "        contents = article2.select('div.st')[0].text.replace('\\xa0', '')\n",
    "        data.append([datetime.now(), keyword, page, link, title, press, date, contents])\n",
    "    result.append(pd.DataFrame(data))\n",
    "\n",
    "# 수집 결과 집계\n",
    "df = pd.concat(result)\n",
    "df.columns = ['BASEDATE', 'KEYWORD', 'PAGE', 'LINK', 'TITLE', 'PRESS', 'DATE', 'CONTENTS']\n",
    "\n",
    "# 데이터 저장\n",
    "writer = pd.ExcelWriter('./result/google_search_{}_{}.xlsx'.format(basedate, keyword))\n",
    "df.to_excel(writer, index=False)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
